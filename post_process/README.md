# 完结篇！OCR深度实践系列（五）：后处理篇

**OCR深度实践系列：**

**（一）[图像预处理](http://mp.weixin.qq.com/s?__biz=MzI5MjYzNzAyMw==&mid=2247484153&idx=1&sn=b65e9e99047ae20ed44cd99e4b0ff2e0&chksm=ec7f12c9db089bdf84281eaa54dad96679fa15b4c915d739597a57885625bc9a1fef15b8b52e&scene=21#wechat_redirect)**

**（二）[数据生成](http://mp.weixin.qq.com/s?__biz=MzI5MjYzNzAyMw==&mid=2247484187&idx=1&sn=549b68ec989792ad5e2fb9179af55598&chksm=ec7f132bdb089a3d2f96ebecc780a6e756cdf26cb4e8a5bc4951c029e0c4dfb83c40cdc927ff&scene=21#wechat_redirect)**

**（三）文本检测**

**（四）文本识别**

间隔一个月，对话系统全流程打通后终于有时间写OCR系列的最后一篇-后处理章节。这一部分可以说才是NLP发挥最大作用的模块，若前面的文本识别效果不好，就可借助NLP的强大能力进行结果修正以及信息结构化。到了这里就体现出兼并OCR和NLP双型技术人的强大之处了。

**本文项目地址：https://github.com/Vincent131499/Chinese-OCR3/tree/master/post_process**

在实际应用场景中，仅仅得到文字识别结果并不意味着问题的解决，比如身份证识别结果中存在错字、无效字符等信息；发票和报销单据识别结果需要定位到每个条目的内容和价格，形成结构化信息。为了解决这些问题，接下来本文将分为两大分支进行介绍：文本纠错和文本结构化。

## 1.文本纠错

文本纠错的目标是纠正OCR输出文本中错误的文字，通常是基于先验信息来达到纠正的目的。当前文本纠错一般应用于机器翻译、Speech2Text(语音转文本)、输入法等，其类型分为以下三类：

1)）词法错误：词语级别的错误，常见于形近字或者音近字；

2）句法错误：与语法相关的错误，常见于语病句子；

3）知识错误：与特定领域现有知识发生矛盾。

在OCR文字识别中往往只涉及到简单的第一类词法错误，比如身份证识别结果将“上海市”错误识别为“上海币”。在实际OCR的后处理应用中，大多数情况下根据先验词典即可解决。

经典的解决算法有两类：1）基于先验词典的改进BK-tree；2）基于语言模型的纠错机制。

得益于深度学习的迅猛发展，目前工业界更加倾向于使用语言模型进行中文纠错，如知名的[pycorrector](https://github.com/shibing624/pycorrector)就是基KenLM语言模型进行纠错的。而近两年随着BERT的强势兴起，一系列基于BERT的中文纠错模型陆续上线，如SoftMaskBERT。

## 2.文本结构化

### 2.1 版面分析

版面分析（Layout Analysis）技术常见于文档识别应用中，是文档信息理解的重要步骤，可以对文档内的图像、文本、公式、表格信息和位置关系进行自动分析、识别和理解。通过版面分析，可以获得文档的逻辑结构，如文本块、段落、行以及表格的位置。

![版面分析效果](E:\my_code\算法平台研发\OCR组件研发\基于深度学习的文字识别教程\chinese-ocr3-back\post_process\images\版面分析效果.gif)

目前大多数的都是用规则引擎来做，但随着业务量增大规则将不能满足需求，端到端的版面分析模型也应运而生。

但是在将文档图片输入到模型之前有研究者发现存在图像扭曲的现象，因此又出来了文档恢复这一方向，用于将扭曲的文档图像进行还原。

针对这块的具体算法没有具体介绍，只是罗列一些常规知识点，使得读者在遇到类似问题时能够知道解决的方向，而不是一头雾水。

### 2.2 NLP集成

在得到文本识别的结果后，对于版面分析要求不高的业务应用，通常可以借助NLP相关工具来得到结构化信息。通常有以下两种做法：

（1）规则模板解析

以身份证识别为例，对于识别结果可以借助正则表达式来高效抽取“身份证号”、“性别”、“地址”这样的特征明显的信息。而且对于这样的信息，规则维护起来也很容易，很少会发生变化，不像“姓名”没有固定的特征表达形式。

（2）NLP信息抽取

同样以身份证识别为例，对于识别结果可以借助NLP信息抽取工具来得到结构化信息，如使用针对身份证信息训练的命名实体识别模型即可端到端的抽取出“姓名”、“性别”、“地址”等所有的信息。也可以借助分类模型来识别出各段文本对应的类型，随后将对应类型结果拼接，通过这种方式也能得到结构化信息。重点是如何灵活的运用NLP信息抽取工具了。

## 3.总结

至此，OCR深度实践系列的所有篇章已完成。刚开始决定动笔写这一系列的时候是因为目前并没有一套介绍OCR的完善体系，想借此梳理OCR的同时也分享给大家一起学习。

后续我将不断更新github的项目资源，从普遍的票证识别延伸到文档识别应用，与君共勉！